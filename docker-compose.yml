version: '3.8'

services:
  redis:
    image: redis:6
    ports:
      - "6379:6379"
    restart: always

  api:
    build:
      context: .
      dockerfile: api/Dockerfile
    ports:
      - "8000:8000"
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
    depends_on:
      - redis
    restart: always

  worker:
    build:
      context: .
      dockerfile: agentic_worker/Dockerfile
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
    depends_on:
      - redis
    restart: always

  # mcp:
  #   build:
  #     context: .
  #     dockerfile: mcp_server/Dockerfile
  #   ports:
  #     - "9000:9000"
  #   depends_on:
  #     - redis
  #   restart: always

# LM Studio (Llama 3) should be run separately on the host (default port 1234) 